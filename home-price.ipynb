{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10211,"databundleVersionId":111096,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:11:30.857119Z","iopub.execute_input":"2025-04-01T21:11:30.857557Z","iopub.status.idle":"2025-04-01T21:11:32.184962Z","shell.execute_reply.started":"2025-04-01T21:11:30.857488Z","shell.execute_reply":"2025-04-01T21:11:32.183735Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Libraries to help with data visualization\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n# Libraries to split data, impute missing values\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nfrom sklearn.impute import SimpleImputer\n\n# Libraries to import decision tree classifier and different ensemble classifiers\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, AdaBoostRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:11:32.186893Z","iopub.execute_input":"2025-04-01T21:11:32.187342Z","iopub.status.idle":"2025-04-01T21:11:35.081876Z","shell.execute_reply.started":"2025-04-01T21:11:32.187312Z","shell.execute_reply":"2025-04-01T21:11:35.080851Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/home-data-for-ml-course/test.csv')\ntest_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:11:35.083207Z","iopub.execute_input":"2025-04-01T21:11:35.083896Z","iopub.status.idle":"2025-04-01T21:11:35.160976Z","shell.execute_reply.started":"2025-04-01T21:11:35.083837Z","shell.execute_reply":"2025-04-01T21:11:35.159730Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/home-data-for-ml-course/train.csv')\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:11:35.162112Z","iopub.execute_input":"2025-04-01T21:11:35.162734Z","iopub.status.idle":"2025-04-01T21:11:35.221295Z","shell.execute_reply.started":"2025-04-01T21:11:35.162684Z","shell.execute_reply":"2025-04-01T21:11:35.220193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numerical = data.select_dtypes(include=['number'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:11:35.222340Z","iopub.execute_input":"2025-04-01T21:11:35.222691Z","iopub.status.idle":"2025-04-01T21:11:35.227363Z","shell.execute_reply.started":"2025-04-01T21:11:35.222656Z","shell.execute_reply":"2025-04-01T21:11:35.226576Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corr_matrix = numerical.corr()\n\n# Extract the correlation of target variable with other features\ntarget_corr = corr_matrix[['SalePrice']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:11:35.230202Z","iopub.execute_input":"2025-04-01T21:11:35.230486Z","iopub.status.idle":"2025-04-01T21:11:35.265892Z","shell.execute_reply.started":"2025-04-01T21:11:35.230458Z","shell.execute_reply":"2025-04-01T21:11:35.264629Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8, 12))\nsns.heatmap(target_corr,annot=True,vmin=-1,vmax=1);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:11:35.267686Z","iopub.execute_input":"2025-04-01T21:11:35.268049Z","iopub.status.idle":"2025-04-01T21:11:36.111775Z","shell.execute_reply.started":"2025-04-01T21:11:35.268007Z","shell.execute_reply":"2025-04-01T21:11:36.110643Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_id = data['Id']\ntest_id = test_data['Id']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:11:36.112755Z","iopub.execute_input":"2025-04-01T21:11:36.113042Z","iopub.status.idle":"2025-04-01T21:11:36.118232Z","shell.execute_reply.started":"2025-04-01T21:11:36.113016Z","shell.execute_reply":"2025-04-01T21:11:36.116797Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:11:36.119765Z","iopub.execute_input":"2025-04-01T21:11:36.120100Z","iopub.status.idle":"2025-04-01T21:11:36.144990Z","shell.execute_reply.started":"2025-04-01T21:11:36.120070Z","shell.execute_reply":"2025-04-01T21:11:36.143807Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = data.drop('SalePrice', axis=1)  # Replace 'target_column' with your target\ny = data['SalePrice']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:11:36.146071Z","iopub.execute_input":"2025-04-01T21:11:36.146416Z","iopub.status.idle":"2025-04-01T21:11:36.166928Z","shell.execute_reply.started":"2025-04-01T21:11:36.146379Z","shell.execute_reply":"2025-04-01T21:11:36.165647Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_features = X.select_dtypes(include=[np.number]).columns.tolist()\ncat_features = X.select_dtypes(exclude=[np.number]).columns.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:11:36.168083Z","iopub.execute_input":"2025-04-01T21:11:36.168402Z","iopub.status.idle":"2025-04-01T21:11:36.187956Z","shell.execute_reply.started":"2025-04-01T21:11:36.168365Z","shell.execute_reply":"2025-04-01T21:11:36.186721Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, StandardScaler, PowerTransformer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:11:36.189012Z","iopub.execute_input":"2025-04-01T21:11:36.189307Z","iopub.status.idle":"2025-04-01T21:11:36.207331Z","shell.execute_reply.started":"2025-04-01T21:11:36.189279Z","shell.execute_reply":"2025-04-01T21:11:36.206193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nX_encoded = encoder.fit_transform(X[cat_features])\ntest_encoded = encoder.transform(test_data[cat_features])\n\n# Convert encoded categorical features into DataFrame\nencoded_feature_names = encoder.get_feature_names_out(cat_features)\nX_encoded = pd.DataFrame(X_encoded, columns=encoded_feature_names)\ntest_encoded = pd.DataFrame(test_encoded, columns=encoded_feature_names)\n\n# Drop original categorical columns and merge encoded ones\nX = X.drop(columns=cat_features).reset_index(drop=True)\ntest_data = test_data.drop(columns=cat_features).reset_index(drop=True)\nX = pd.concat([X, X_encoded], axis=1)\ntest_data = pd.concat([test_data, test_encoded], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:11:36.208334Z","iopub.execute_input":"2025-04-01T21:11:36.208756Z","iopub.status.idle":"2025-04-01T21:11:36.319778Z","shell.execute_reply.started":"2025-04-01T21:11:36.208696Z","shell.execute_reply":"2025-04-01T21:11:36.318580Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.impute import SimpleImputer, KNNImputer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:11:36.320777Z","iopub.execute_input":"2025-04-01T21:11:36.321092Z","iopub.status.idle":"2025-04-01T21:11:36.378847Z","shell.execute_reply.started":"2025-04-01T21:11:36.321057Z","shell.execute_reply":"2025-04-01T21:11:36.377820Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_transformer = Pipeline([\n    ('imputer', KNNImputer(n_neighbors=5)),  # More advanced imputation\n    ('scaler', StandardScaler()),\n    ('power', PowerTransformer(method='yeo-johnson'))\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:11:36.379879Z","iopub.execute_input":"2025-04-01T21:11:36.380140Z","iopub.status.idle":"2025-04-01T21:11:36.384589Z","shell.execute_reply.started":"2025-04-01T21:11:36.380119Z","shell.execute_reply":"2025-04-01T21:11:36.383775Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X[num_features] = num_transformer.fit_transform(X[num_features])\ntest_data[num_features] = num_transformer.transform(test_data[num_features])\n\n# Feature selection model\nfeature_selector = SelectFromModel(RandomForestRegressor(n_estimators=100, random_state=42))\nX_selected = feature_selector.fit_transform(X, y)\ntest_selected = feature_selector.transform(test_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:11:36.385525Z","iopub.execute_input":"2025-04-01T21:11:36.385848Z","iopub.status.idle":"2025-04-01T21:11:40.583806Z","shell.execute_reply.started":"2025-04-01T21:11:36.385820Z","shell.execute_reply":"2025-04-01T21:11:40.582640Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_selected, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:11:40.584992Z","iopub.execute_input":"2025-04-01T21:11:40.585299Z","iopub.status.idle":"2025-04-01T21:11:40.592103Z","shell.execute_reply.started":"2025-04-01T21:11:40.585272Z","shell.execute_reply":"2025-04-01T21:11:40.590796Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nfrom sklearn.model_selection import GridSearchCV","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:11:40.595974Z","iopub.execute_input":"2025-04-01T21:11:40.596312Z","iopub.status.idle":"2025-04-01T21:11:40.614414Z","shell.execute_reply.started":"2025-04-01T21:11:40.596283Z","shell.execute_reply":"2025-04-01T21:11:40.613183Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom catboost import CatBoostRegressor\n\n# # Define models\nmodels = []\nmodels.append((\"Random Forest\", RandomForestRegressor(random_state=1)))\nmodels.append((\"Linear Regression\", LinearRegression()))\nmodels.append((\"Bagging\", BaggingRegressor(random_state=1)))\nmodels.append((\"Ada Boost\", AdaBoostRegressor(random_state=1)))\nmodels.append((\"Gradient Boost\", GradientBoostingRegressor(random_state=1)))\nmodels.append((\"cat Boost\",CatBoostRegressor(random_seed=42, verbose=200)))\nmodels.append((\"XG Boost\", XGBRegressor(random_state=1, eval_metric=\"rmse\")))\n\nresults1 = []\nnames = []\n\nprint(\"\\nCross-Validation performance on training dataset:\\n\")\nkfold = KFold(n_splits=5, shuffle=True, random_state=1)\n\nfor name, model in models:\n    cv_result = cross_val_score(model, X_train, y_train, scoring=\"r2\", cv=kfold)\n    results1.append(cv_result)\n    names.append(name)\n    print(f\"{name}: Mean R² = {cv_result.mean():.4f}\")\n\nprint(\"\\nValidation Performance:\\n\")\nfor name, model in models:\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_val)\n    \n    rmse = mean_squared_error(y_val, y_pred, squared=False)\n    mae = mean_absolute_error(y_val, y_pred)\n    r2 = r2_score(y_val, y_pred)\n    \n    print(f\"{name} - RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:11:40.616082Z","iopub.execute_input":"2025-04-01T21:11:40.616444Z","iopub.status.idle":"2025-04-01T21:12:07.862835Z","shell.execute_reply.started":"2025-04-01T21:11:40.616409Z","shell.execute_reply":"2025-04-01T21:12:07.861952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# rf_tuned = RandomForestRegressor(random_state=1)\n\n# parameters = {\n#     'n_estimators': [300, 400, 350],\n#     'max_depth': [ 20, 30],\n#     'min_samples_split': [ 5, 10],\n#     'min_samples_leaf': [2, 4],\n#     'bootstrap': [True, False],\n#     'max_features': ['sqrt', 'log2', 0.5, 1]\n# }\n\n# # Run the grid search\n# grid_obj = GridSearchCV(rf_tuned, parameters, scoring='r2',cv=5,n_jobs=-1)\n# grid_obj = grid_obj.fit(X_train, y_train)\n\n# # Set the clf to the best combination of parameters\n# rf_tuned = grid_obj.best_estimator_\n\n# # Fit the best algorithm to the data.\n# rf_tuned.fit(X_train, y_train)\n\n# y_pred = rf_tuned.predict(X_val)\n    \n# rmse = mean_squared_error(y_val, y_pred, squared=False)\n# mae = mean_absolute_error(y_val, y_pred)\n# r2 = r2_score(y_val, y_pred)\n    \n# print(f\"RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:12:07.863561Z","iopub.execute_input":"2025-04-01T21:12:07.863813Z","iopub.status.idle":"2025-04-01T21:12:07.869019Z","shell.execute_reply.started":"2025-04-01T21:12:07.863791Z","shell.execute_reply":"2025-04-01T21:12:07.867418Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# xgb_tuned = XGBRegressor(random_state=1, eval_metric=\"rmse\")\n\n# parameters = {\n#     'n_estimators': [300, 400, 500],\n#     'learning_rate': [0.001, 0.01, 0.05],\n#     'max_depth': [ 7, 8],\n#     'subsample': [0.6, 0.8],\n#     'colsample_bytree': [0.6, 0.8]\n# }\n\n# # Run the grid search\n# grid_obj = GridSearchCV(xgb_tuned, parameters, scoring='r2',cv=5,n_jobs=-1)\n# grid_obj = grid_obj.fit(X_train, y_train)\n\n# # Set the clf to the best combination of parameters\n# xgb_tuned = grid_obj.best_estimator_\n\n# # Fit the best algorithm to the data.\n# xgb_tuned.fit(X_train, y_train)\n\n# y_pred = xgb_tuned.predict(X_val)\n    \n# rmse = mean_squared_error(y_val, y_pred, squared=False)\n# mae = mean_absolute_error(y_val, y_pred)\n# r2 = r2_score(y_val, y_pred)\n    \n# print(f\"RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:12:07.870474Z","iopub.execute_input":"2025-04-01T21:12:07.870964Z","iopub.status.idle":"2025-04-01T21:12:07.907331Z","shell.execute_reply.started":"2025-04-01T21:12:07.870927Z","shell.execute_reply":"2025-04-01T21:12:07.906238Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# gb_tuned = GradientBoostingRegressor(random_state=1)\n\n# parameters = {\n#     'n_estimators': [700,800,900],\n#     'learning_rate': [0.001, 0.003, 0.005],\n#     'max_depth': [ 10,11],\n#     'min_samples_split': [20,25],\n#     'subsample': [0.75, 0.85,0.95]\n# }\n\n# # Run the grid search\n# grid_obj = GridSearchCV(gb_tuned, parameters, scoring='r2',cv=5,n_jobs=-1)\n# grid_obj = grid_obj.fit(X_train, y_train)\n\n# # Set the clf to the best combination of parameters\n# gb_tuned = grid_obj.best_estimator_\n\n# # Fit the best algorithm to the data.\n# gb_tuned.fit(X_train, y_train)\n\n# y_pred = gb_tuned.predict(X_val)\n    \n# rmse = mean_squared_error(y_val, y_pred, squared=False)\n# mae = mean_absolute_error(y_val, y_pred)\n# r2 = r2_score(y_val, y_pred)\n\n# print(f\"Best Parameters: {grid_search.best_params_}\")\n# print(f\"RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:12:07.908625Z","iopub.execute_input":"2025-04-01T21:12:07.908954Z","iopub.status.idle":"2025-04-01T21:12:07.925853Z","shell.execute_reply.started":"2025-04-01T21:12:07.908925Z","shell.execute_reply":"2025-04-01T21:12:07.924737Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"catboost_tuned = CatBoostRegressor(random_seed=42, verbose=200, \n                                   learning_rate = 0.03,\n                                   n_estimators = 1300, \n                                   depth = 12, \n                                   subsample = 0.8, \n                                   l2_leaf_reg = 5,\n                                   boosting_type=\"Ordered\"\n                                  )\ncatboost_tuned.fit(X_train, y_train)\n\ny_pred = catboost_tuned.predict(X_val)\n\nrmse = mean_squared_error(y_val, y_pred, squared=False)\nmae = mean_absolute_error(y_val, y_pred)\nr2 = r2_score(y_val, y_pred)\n\nprint(f\"RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:12:07.926991Z","iopub.execute_input":"2025-04-01T21:12:07.927316Z","iopub.status.idle":"2025-04-01T21:28:42.680720Z","shell.execute_reply.started":"2025-04-01T21:12:07.927289Z","shell.execute_reply":"2025-04-01T21:28:42.679641Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# catboost_tuned = CatBoostRegressor(random_seed=42, verbose=200)\n\n# parameters = {\n#     'n_estimators': [1300, 1400,1500],\n#     'learning_rate': [0.01, 0.03],\n#     'depth': [12,13,14],\n#     'l2_leaf_reg': [3, 5],\n#     'subsample': [0.8, 0.9]\n# },\n\n# grid_obj = GridSearchCV(catboost_tuned,parameters,scoring='r2',cv=5,n_jobs=-1)\n# grid_obj = grid_obj.fit(X_train, y_train)\n\n# # Best model\n# catboost_tuned = grid_obj.best_estimator_\n\n# # Fit on training data\n# catboost_tuned.fit(X_train, y_train)\n\n# # Predict on validation data\n# y_pred = catboost_tuned.predict(X_val)\n\n# # Evaluate performance\n# rmse = mean_squared_error(y_val, y_pred, squared=False)\n# mae = mean_absolute_error(y_val, y_pred)\n# r2 = r2_score(y_val, y_pred)\n\n# print(f\"Best Parameters: {grid_search.best_params_}\")\n# print(f\"RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:28:42.681772Z","iopub.execute_input":"2025-04-01T21:28:42.682125Z","iopub.status.idle":"2025-04-01T21:28:42.686348Z","shell.execute_reply.started":"2025-04-01T21:28:42.682092Z","shell.execute_reply":"2025-04-01T21:28:42.685379Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = catboost_tuned.predict(test_selected)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:28:42.687420Z","iopub.execute_input":"2025-04-01T21:28:42.687745Z","iopub.status.idle":"2025-04-01T21:28:42.718167Z","shell.execute_reply.started":"2025-04-01T21:28:42.687720Z","shell.execute_reply":"2025-04-01T21:28:42.716856Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"selected_columns = pd.DataFrame({\n    'Id': test_id,\n    'SalePrice': y_pred\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:28:42.719236Z","iopub.execute_input":"2025-04-01T21:28:42.719550Z","iopub.status.idle":"2025-04-01T21:28:42.732599Z","shell.execute_reply.started":"2025-04-01T21:28:42.719524Z","shell.execute_reply":"2025-04-01T21:28:42.731586Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"selected_columns.to_csv('selected_columns.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:28:42.733660Z","iopub.execute_input":"2025-04-01T21:28:42.733950Z","iopub.status.idle":"2025-04-01T21:28:42.757996Z","shell.execute_reply.started":"2025-04-01T21:28:42.733925Z","shell.execute_reply":"2025-04-01T21:28:42.756963Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# Path to your file\nfile_path = 'selected_columns.csv'\n\n# Generate and display the download link\nFileLink(file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T21:28:42.758837Z","iopub.execute_input":"2025-04-01T21:28:42.759095Z","iopub.status.idle":"2025-04-01T21:28:42.766438Z","shell.execute_reply.started":"2025-04-01T21:28:42.759070Z","shell.execute_reply":"2025-04-01T21:28:42.765584Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}